{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04942733",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U transformers accelerate\n",
    "%pip install pillow\n",
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdf25041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1cd24f9e29460d97284e352b13b46b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4608e0af4c5141e19eeaa6c4734e4be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00005.safetensors:  67%|######7   | 3.30G/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4c360621774943ba1d8539d3c12ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00005.safetensors:  66%|######5   | 3.26G/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6490a70b48a941d88608c82662a0964d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00005.safetensors:  65%|######4   | 3.23G/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d97d38a591604428931b122b93ba174c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00005.safetensors:  64%|######3   | 3.18G/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd18c2383c640fab858ffe3dd53591a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19842ee4a23145ad9db7e39ba64c1887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu and disk.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import MllamaForConditionalGeneration, AutoProcessor, pipeline\n",
    "\n",
    "\n",
    "base_model = \"meta-llama/Llama-3.2-11B-Vision-Instruct\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(base_model)\n",
    "\n",
    "model = MllamaForConditionalGeneration.from_pretrained(\n",
    "    base_model,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ca33f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "<|image|>Describe the tutorial feature image.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "The image is a graphic for an AI application, with the title \"Build & Deploy AI Application with o1\" in green text on a green background. The purpose of the image is to promote the use of o1, a platform for building and deploying AI applications.\n",
      "\n",
      "Here are the key elements of the image:\n",
      "\n",
      "* **Title**: \n",
      "\t+ Text: \"Build & Deploy AI Application with o1\"\n",
      "\t+ Color: Green\n",
      "\t+ Font: Simple, sans-serif font\n",
      "* **Logo**:\n",
      "\t+ Color: Dark blue\n",
      "\t+ Shape: A stylized letter \"o\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "url = \"https://lh7-rt.googleusercontent.com/docsz/AD_4nXcz-J3iR2bEGcCSLzay07Rqfj5tTakp2EMTTN0x6nKYGLS5yWl0unoSpj2S0-mrWpDtMqjl1fAgH6pVkKJekQEY_kwzL6QNOdf143Yt66znQ0EpfLvx6CLFOqw41oeOYmhPZ6Qrlb5AjEr4AenIOgBMTWTD?key=vhLUYntaS9QOx531XpJH3g\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"image\"},\n",
    "        {\"type\": \"text\", \"text\": \"Describe the tutorial feature image.\"}\n",
    "    ]}\n",
    "]\n",
    "input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = processor(image, input_text, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "output = model.generate(**inputs, max_new_tokens=120)\n",
    "print(processor.decode(output[0]))\n",
    "#==============output=================\n",
    "# <|begin_of_text|><|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "# <|image|>Describe the tutorial feature image.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "# The image is a graphic for an AI application, with the title \"Build & Deploy AI Application with o1\" in green text on a green background. The purpose of the image is to promote the use of o1, a platform for building and deploying AI applications.\n",
    "\n",
    "# Here are the key elements of the image:\n",
    "\n",
    "# * **Title**: \n",
    "# \t+ Text: \"Build & Deploy AI Application with o1\"\n",
    "# \t+ Color: Green\n",
    "# \t+ Font: Simple, sans-serif font\n",
    "# * **Logo**:\n",
    "# \t+ Color: Dark blue\n",
    "# \t+ Shape: A stylized letter \"o"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
